---
layout:     post
title:      "nlp预处理"
subtitle:   " moses"
date:       2019-11-29 16:30:00
author:     "TerryRen"
header-img: "img/post-bg-2015.jpg"
catalog: true
tags:
    - nlp
---

首先将moses工具包下载到本地：
```
git clone https://github.com/moses-smt/mosesdecoder.git
```
进入下载好mosesdecoder的文件夹，将并创建data文件夹，将要预处理的语料文件（此处以训练文件trian_en和train_zh为例）放入data文件夹，然后并打开终端。
# normalize-punctuation
normalize-punctuation就是做一个符号或者拼写标准化的过程，例如出现的中文符号会统一的转化为英文符号，一些稀奇古怪的拼写形式会转化为标准的字母。具体的处理我们使用moses提供的方法。
```
perl scripts/tokenizer/normalize-punctuation.perl -l en < data/train_en > data/train-norm.en
```
# tokenizer
该步骤就是对英文进行分词，和汉字中的结巴分词功能一样，正常情况下英文分词只需要按照空格进行就可以了，但是英文中有一些特殊的情况需要进行处理，举例说明比如标点符号和单词之间一般是没有空格的，而我们分词的时候也需要将它区分出来。
在执行此操作前，可以进入perl脚本中修改thread的数量。
```
perl scripts/tokenizer/tokenizer.perl -a -l en < data/train-norm.en > data/trian-tok.en
```
# truecase
我们观察英文语料时会发现数据中存在大量的大小写不统一的情况，有些时候大小写不同会有不同的含义，而有些时候大小写不同只是因为单词所处的语境所决定的。最简单的例子就是英文中的首字母都会进行大写处理，而一些特殊单词比如I本身就是大写的。我们通过truecase可以将单词大小写统一为他本来的形式。
第一步需要训练一个truecase的模型，这个模型包含了各个单词对应的大小写形式。
```
perl scripts/recaser/train-truecaser.perl --model en-truecase.mdl --corpus data/train-tok.en
```
第二步使用我们训练好的模型。
```
perl scripts/recaser/truecase.perl --model en-truecase.mdl < data/train-tok.en > data/train-tc.en
```
# jieba
中文的分词工具有很多，在这里我们使用最基本的结巴分词，作为中文分词的工具。
```python
python -m jieba -d < data/trian_zh > data/test-jieba.zh
```
# clean-corpus-n
清理平行语料中语句长度过长的数据，不管中文语料还是英文中出现长度超过100的平行数据都会被删除。
```
mv data/en.tc.all data/train-enzh.en
mv data/zh.jieba.all data/trian-enzh.zh
perl scripts/training/clean-corpus-n.perl data/trian-enzh zh en data/train-clean 1 100
```
